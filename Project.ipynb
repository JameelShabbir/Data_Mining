{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Project-Facial Recognization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>1 Import the required libraries:\n",
    "\n",
    "<h6>We'll begin by importing the necessary libraries for the project:\n",
    "In this step, we import the necessary Python libraries to work with our project. We import numpy for handling numerical data in arrays, tensorflow for building and training machine learning models, and keras as a high-level neural networks API built on top of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>2 Load the datasets:\n",
    "<h6>Load the training and testing datasets from the provided files:\n",
    "We load the training and testing datasets from the provided files using the np.load() function from NumPy. The data is loaded into train_images, train_labels, test_images, and test_labels variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load(f'./facial_data/train_images.npy')\n",
    "train_labels = np.load(f'./facial_data/train_labels.npy')\n",
    "test_images =  np.load(f'./facial_data/test_images.npy')\n",
    "test_labels =  np.load(f'./facial_data/test_labels.npy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>3 Preprocess the data:\n",
    "<h6>Preprocess the data by normalizing the pixel values and converting labels to one-hot encoded format:\n",
    "In this step, we preprocess the data to prepare it for training the model. We normalize the pixel values of the images to be in the range [0, 1] by dividing them by 255.0, as the original pixel values are integers ranging from 0 to 255. Additionally, we adjust the labels to start from 0 by subtracting 1 from all label values. Then, we convert the labels to one-hot encoded format using keras.utils.to_categorical(). This step is necessary for training the neural network, as it converts the labels into a binary matrix representation suitable for multi-class classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in training data: [0 1 2 3 4 5 6]\n",
      "Unique labels in testing data: [0 1 2 3 4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# Normalize pixel values to range [0, 1]\n",
    "train_images = train_images.astype('float32') / 255.0\n",
    "test_images = test_images.astype('float32') / 255.0\n",
    "\n",
    "# Adjust labels to start from 0 (subtract 1 from all label values)\n",
    "train_labels = train_labels - 1\n",
    "test_labels = test_labels - 1\n",
    "\n",
    "# Check the unique labels in the training dataset\n",
    "unique_labels_train = np.unique(train_labels)\n",
    "print(\"Unique labels in training data:\", unique_labels_train)\n",
    "\n",
    "# Check the unique labels in the testing dataset\n",
    "unique_labels_test = np.unique(test_labels)\n",
    "print(\"Unique labels in testing data:\", unique_labels_test)\n",
    "\n",
    "# Convert labels to one-hot encoded format\n",
    "num_classes = len(np.unique(train_labels))\n",
    "train_labels = keras.utils.to_categorical(train_labels, num_classes)\n",
    "test_labels = keras.utils.to_categorical(test_labels, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>4 Build the ConvNet model:\n",
    "<h6>Build a Convolutional Neural Network model using Keras:\n",
    "In this step, we build the Convolutional Neural Network (ConvNet) model using Keras. A ConvNet is a type of neural network particularly effective for computer vision tasks, as it can automatically learn hierarchical patterns and features from images. The model architecture consists of multiple Conv2D layers with ReLU activation for feature extraction, followed by MaxPooling2D layers for downsampling, and finally, Dense layers for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image height: 48\n",
      "Image width: 48\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 46, 46, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 23, 23, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 21, 21, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 10, 10, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1048704   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 7)                 903       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1142279 (4.36 MB)\n",
      "Trainable params: 1142279 (4.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Determine the image size from the data\n",
    "image_height, image_width = train_images.shape[1], train_images.shape[2]\n",
    "print(\"Image height:\", image_height)\n",
    "print(\"Image width:\", image_width)\n",
    "\n",
    "# Build the ConvNet model\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_height, image_width, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>5 Compile the model:\n",
    "<h6>Compile the model with an appropriate optimizer and loss function:\n",
    "After building the model, we need to compile it before training. Compiling the model involves specifying the optimizer, loss function, and evaluation metrics. In this case, we use the \"adam\" optimizer, which is an adaptive learning rate optimization algorithm, the \"categorical_crossentropy\" loss function, suitable for multi-class classification problems, and we track the \"accuracy\" metric during training to monitor the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>6 Train the model:\n",
    "<h6>Train the model on the training data:\n",
    "In this step, we train the model on the preprocessed training data using the model.fit() function. We specify the batch size (the number of samples per gradient update) and the number of epochs (the number of times the entire dataset will be passed through the network during training). The model is trained to learn the patterns and features in the images and make accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "404/404 [==============================] - 125s 302ms/step - loss: 1.5995 - accuracy: 0.3441 - val_loss: 4.2837 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/2\n",
      "404/404 [==============================] - 132s 325ms/step - loss: 1.3882 - accuracy: 0.4585 - val_loss: 4.0445 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x147c45139d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 2\n",
    "\n",
    "model.fit(train_images, train_labels, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>7 Evaluate the model:\n",
    "<h6>Evaluate the model on the test data:\n",
    "Once the model is trained, we evaluate its performance on the test data using the model.evaluate() function. This step computes the loss and accuracy of the model on the unseen test data to assess its generalization and ability to make accurate predictions on new, unseen samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4352187216281891\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(f'Test accuracy: {test_accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>8 Make predictions:\n",
    "<h6>You can use the trained model to make predictions on new images:\n",
    "After training and evaluation, we can use the trained model to make predictions on new images using the model.predict() function. The model takes the input images and outputs the predicted probabilities for each class label. The class label with the highest probability is considered the final prediction for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 15s 64ms/step\n",
      "[[0.26512077 0.03187996 0.27766496 ... 0.01653384 0.23267281 0.00413744]\n",
      " [0.32122222 0.01826053 0.26650032 ... 0.07093739 0.22788034 0.00406726]\n",
      " [0.43942636 0.04430061 0.24991037 ... 0.04836881 0.12296793 0.01260502]\n",
      " ...\n",
      " [0.29490873 0.03356543 0.3738431  ... 0.02188653 0.05044347 0.01776687]\n",
      " [0.05189067 0.00460207 0.36563796 ... 0.34553158 0.16967703 0.04566986]\n",
      " [0.03638849 0.01263612 0.17500986 ... 0.4580842  0.07110635 0.01836206]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.5154639175257731%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy = {tru/(tru+fls)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
